{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyN7fSYlj/fdfhfsKRzhbNDl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vigneshK0404/NOva_Fitter_CNF/blob/main/CNF_Modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchinfo\n",
        "!pip install nflows"
      ],
      "metadata": {
        "id": "6k71TZgr1wJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchinfo\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "import time"
      ],
      "metadata": {
        "id": "u0LTB28WBXUH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nflows.flows.base import Flow  # a container for full Flow\n",
        "from nflows.distributions.normal import StandardNormal  # Gaussian latent space distribution\n",
        "from nflows.transforms.base import (\n",
        "    CompositeTransform,\n",
        ")  # a wrapper to stack simpler transformations to form a more complex one\n",
        "from nflows.transforms.autoregressive import (\n",
        "    MaskedAffineAutoregressiveTransform,\n",
        ")  # the basic transformation, which we will stack several times\n",
        "from nflows.transforms.autoregressive import (\n",
        "    MaskedPiecewiseRationalQuadraticAutoregressiveTransform,\n",
        ")  # the basic transformation, which we will stack several times\n",
        "from nflows.transforms.permutations import ReversePermutation # a layer that simply reverts the order of outputs"
      ],
      "metadata": {
        "id": "7Og_cDFsBf5v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.device_count())\n",
        "dnumber = 0\n",
        "device = torch.device(f\"cuda:{dnumber}\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "device_name = torch.cuda.get_device_name(dnumber)\n",
        "print(device_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNX990ErBhyW",
        "outputId": "6165cf55-6db8-4149-cf0c-0ea61a7328d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "1\n",
            "cuda:0\n",
            "NVIDIA A100-SXM4-80GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gauss(N,mu,sig,x):\n",
        "    N_t = N.reshape(-1,1)\n",
        "    mu_t = mu.reshape(-1,1)\n",
        "    sig_t = sig.reshape(-1,1)\n",
        "\n",
        "    term1 = N_t / (sig_t * np.sqrt(2 * np.pi))\n",
        "    term2 = np.exp(-0.5 * np.square((x - mu_t) / sig_t))\n",
        "    return np.array(term1 * term2)\n",
        "\n",
        "\n",
        "def generatePrior(sampleSize):\n",
        "    N1 = np.random.uniform(10,50,sampleSize)\n",
        "    N2 = np.random.uniform(10,30,sampleSize)\n",
        "\n",
        "    mu1 = np.random.uniform(1,3,sampleSize)\n",
        "    mu2 = np.random.uniform(5,9,sampleSize)\n",
        "\n",
        "    sig1 = np.random.uniform(1,3,sampleSize)\n",
        "    sig2 = np.random.uniform(5,9,sampleSize)\n",
        "\n",
        "    return N1,mu1,sig1,N2,mu2,sig2\n",
        "\n",
        "\n",
        "def generateTrainingData(uniqueSampleNum, sampleNumber):\n",
        "\n",
        "  N1,mu1,sig1,N2,mu2,sig2 = generatePrior(uniqueSampleNum)\n",
        "\n",
        "  raw = np.arange(0.5,10,1) #startbinCenter, endBinEdge, StepSize [0.5,1.5...9.5]\n",
        "  gaussTotal = gauss(N1,mu1,sig1,raw) + gauss(N2,mu2,sig2,raw)\n",
        "  thetaData = np.column_stack((N1,mu1,sig1,N2,mu2,sig2))\n",
        "\n",
        "  fullGaussMatrix = np.repeat(gaussTotal,repeats=sampleNumber,axis=0)\n",
        "  dataPoisson = np.random.poisson(lam=fullGaussMatrix,size=None).reshape(-1,1)\n",
        "\n",
        "  thetaExtend_len = len(raw)\n",
        "\n",
        "  fullthetaData = np.repeat(thetaData,repeats=sampleNumber*thetaExtend_len,axis=0)\n",
        "\n",
        "  return dataPoisson, fullthetaData\n",
        "\n",
        "dataPoisson, thetaData = generateTrainingData(2,1)\n",
        "\n",
        "print(thetaData)\n",
        "print(dataPoisson)\n"
      ],
      "metadata": {
        "id": "XUvfNJ-U2Eet",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b594074e-686e-4379-8b8e-934cd7a05d72"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [32.83678867  1.01183497  1.1423718  22.47759909  6.38165238  6.38095182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]\n",
            " [11.57838143  1.04847821  1.3638702  10.45193323  7.94432419  5.01185182]]\n",
            "[[ 8]\n",
            " [18]\n",
            " [ 7]\n",
            " [ 4]\n",
            " [ 1]\n",
            " [ 0]\n",
            " [ 0]\n",
            " [ 1]\n",
            " [ 3]\n",
            " [ 0]\n",
            " [ 2]\n",
            " [ 4]\n",
            " [ 2]\n",
            " [ 0]\n",
            " [ 0]\n",
            " [ 0]\n",
            " [ 0]\n",
            " [ 2]\n",
            " [ 1]\n",
            " [ 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t-V9uEAyHCN2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}